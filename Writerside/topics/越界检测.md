# 越界检测


## 姿势估计（YOLO）

训练模型：https://blog.csdn.net/qq_42452134/article/details/135205234

数据集：COCO-Pose

https://docs.ultralytics.com/zh/datasets/pose/coco/#sample-images-and-annotations

### 工具包 {#tools}

**导入库**

    import cv2
    import matplotlib.pyplot as plt

**画图工具**

    def draw(area, results, img_path, dir, labels):
        # 转成整数的 numpy array
        bboxes_xyxy = results[0].boxes.xyxy.cpu().numpy().astype('uint32')
        # print(results[0].keypoints)
        bboxes_keypoints = results[0].keypoints.data.cpu().numpy()
        num_bbox = len(results[0].boxes.cls)
        img_bgr = cv2.imread(img_path)
        plt.imshow(img_bgr[:,:,::-1])
        plt.show()
    
        # 区域框可视化配置
        bbox_color = (0, 0, 255)             # 框的 BGR 颜色
        bbox_thickness = 2                  # 框的线宽
    
        #区域框
        img_bgr = cv2.rectangle(img_bgr, (area[0][0], area[0][1]), (area[1][0], area[1][1]), bbox_color,
                                    bbox_thickness)
        
        # 框（rectangle）可视化配置
        bbox_color = (255, 0, 0)             # 框的 BGR 颜色
        bbox_thickness = 1                  # 框的线宽
        # 框类别文字
        bbox_labelstr = {
            'font_size':0.5,         # 字体大小
            'font_thickness':2,   # 字体粗细
            'offset_x':10,          # X 方向，文字偏移距离，向右为正
            'offset_y':-10,        # Y 方向，文字偏移距离，向下为正
        }
    
        # 关键点 BGR 配色
        kpt_color_map = {
            0: {'name': 'Nose', 'color': [0, 0, 255], 'radius': 6},  # 鼻尖
            1: {'name': 'Right Eye', 'color': [255, 0, 0], 'radius': 6},  # 右边眼睛
            2: {'name': 'Left Eye', 'color': [255, 0, 0], 'radius': 6},  # 左边眼睛
            3: {'name': 'Right Ear', 'color': [0, 255, 0], 'radius': 6},  # 右边耳朵
            4: {'name': 'Left Ear', 'color': [0, 255, 0], 'radius': 6},  # 左边耳朵
            5: {'name': 'Right Shoulder', 'color': [193, 182, 255], 'radius': 6},  # 右边肩膀
            6: {'name': 'Left Shoulder', 'color': [193, 182, 255], 'radius': 6},  # 左边肩膀
            7: {'name': 'Right Elbow', 'color': [16, 144, 247], 'radius': 6},  # 右侧胳膊肘
            8: {'name': 'Left Elbow', 'color': [16, 144, 247], 'radius': 6},  # 左侧胳膊肘
            9: {'name': 'Right Wrist', 'color': [1, 240, 255], 'radius': 6},  # 右侧手腕
            10: {'name': 'Left Wrist', 'color': [1, 240, 255], 'radius': 6},  # 左侧手腕
            11: {'name': 'Right Hip', 'color': [140, 47, 240], 'radius': 6},  # 右侧胯
            12: {'name': 'Left Hip', 'color': [140, 47, 240], 'radius': 6},  # 左侧胯
            13: {'name': 'Right Knee', 'color': [223, 155, 60], 'radius': 6},  # 右侧膝盖
            14: {'name': 'Left Knee', 'color': [223, 155, 60], 'radius': 6},  # 左侧膝盖
            15: {'name': 'Right Ankle', 'color': [139, 0, 0], 'radius': 6},  # 右侧脚踝
            16: {'name': 'Left Ankle', 'color': [139, 0, 0], 'radius': 6},  # 左侧脚踝
        }
    
        # 点类别文字
        kpt_labelstr = {
            'font_size': 1,  # 字体大小
            'font_thickness': 1,  # 字体粗细
            'offset_x': 0,  # X 方向，文字偏移距离，向右为正
            'offset_y': 150,  # Y 方向，文字偏移距离，向下为正
        }
    
        # 骨架连接 BGR 配色
        skeleton_map = [
            {'srt_kpt_id': 15, 'dst_kpt_id': 13, 'color': [0, 100, 255], 'thickness': 1},  # 右侧脚踝-右侧膝盖
            {'srt_kpt_id': 13, 'dst_kpt_id': 11, 'color': [0, 255, 0], 'thickness': 1},  # 右侧膝盖-右侧胯
            {'srt_kpt_id': 16, 'dst_kpt_id': 14, 'color': [255, 0, 0], 'thickness': 1},  # 左侧脚踝-左侧膝盖
            {'srt_kpt_id': 14, 'dst_kpt_id': 12, 'color': [0, 0, 255], 'thickness': 1},  # 左侧膝盖-左侧胯
            {'srt_kpt_id': 11, 'dst_kpt_id': 12, 'color': [122, 160, 255], 'thickness': 1},  # 右侧胯-左侧胯
            {'srt_kpt_id': 5, 'dst_kpt_id': 11, 'color': [139, 0, 139], 'thickness': 1},  # 右边肩膀-右侧胯
            {'srt_kpt_id': 6, 'dst_kpt_id': 12, 'color': [237, 149, 100], 'thickness': 1},  # 左边肩膀-左侧胯
            {'srt_kpt_id': 5, 'dst_kpt_id': 6, 'color': [152, 251, 152], 'thickness': 1},  # 右边肩膀-左边肩膀
            {'srt_kpt_id': 5, 'dst_kpt_id': 7, 'color': [148, 0, 69], 'thickness': 1},  # 右边肩膀-右侧胳膊肘
            {'srt_kpt_id': 6, 'dst_kpt_id': 8, 'color': [0, 75, 255], 'thickness': 1},  # 左边肩膀-左侧胳膊肘
            {'srt_kpt_id': 7, 'dst_kpt_id': 9, 'color': [56, 230, 25], 'thickness': 1},  # 右侧胳膊肘-右侧手腕
            {'srt_kpt_id': 8, 'dst_kpt_id': 10, 'color': [0, 240, 240], 'thickness': 1},  # 左侧胳膊肘-左侧手腕
            {'srt_kpt_id': 1, 'dst_kpt_id': 2, 'color': [224, 255, 255], 'thickness': 1},  # 右边眼睛-左边眼睛
            {'srt_kpt_id': 0, 'dst_kpt_id': 1, 'color': [47, 255, 173], 'thickness': 1},  # 鼻尖-左边眼睛
            {'srt_kpt_id': 0, 'dst_kpt_id': 2, 'color': [203, 192, 255], 'thickness': 1},  # 鼻尖-左边眼睛
            {'srt_kpt_id': 1, 'dst_kpt_id': 3, 'color': [196, 75, 255], 'thickness': 1},  # 右边眼睛-右边耳朵
            {'srt_kpt_id': 2, 'dst_kpt_id': 4, 'color': [86, 0, 25], 'thickness': 1},  # 左边眼睛-左边耳朵
            {'srt_kpt_id': 3, 'dst_kpt_id': 5, 'color': [255, 255, 0], 'thickness': 1},  # 右边耳朵-右边肩膀
            {'srt_kpt_id': 4, 'dst_kpt_id': 6, 'color': [255, 18, 200], 'thickness': 1}  # 左边耳朵-左边肩膀
        ]
        # %%
        for idx in range(num_bbox):  # 遍历每个框
            if labels[idx] == False:
                continue
            # 获取该框坐标
            bbox_xyxy = bboxes_xyxy[idx]
            # 获取框的预测类别（对于关键点检测，只有一个类别）
            bbox_label = results[0].names[0]
            # 画框
            img_bgr = cv2.rectangle(img_bgr, (bbox_xyxy[0], bbox_xyxy[1]), (bbox_xyxy[2], bbox_xyxy[3]), bbox_color,
                                    bbox_thickness)
            # 写框类别文字：图片，文字字符串，文字左上角坐标，字体，字体大小，颜色，字体粗细
            img_bgr = cv2.putText(img_bgr, bbox_label,
                                  (bbox_xyxy[0] + bbox_labelstr['offset_x'], bbox_xyxy[1] + bbox_labelstr['offset_y']),
                                  cv2.FONT_HERSHEY_SIMPLEX, bbox_labelstr['font_size'], bbox_color,
                                  bbox_labelstr['font_thickness'])
    
            bbox_keypoints = bboxes_keypoints[idx]  # 该框所有关键点坐标和置信度
    
            # 画该框的骨架连接
            for skeleton in skeleton_map:
                # 获取起始点坐标
                srt_kpt_id = skeleton['srt_kpt_id']
                srt_kpt_x = round(bbox_keypoints[srt_kpt_id][0])
                srt_kpt_y = round(bbox_keypoints[srt_kpt_id][1])
                srt_kpt_conf = bbox_keypoints[srt_kpt_id][2]  # 获取起始点置信度
                # print(srt_kpt_conf)
                # 获取终止点坐标
                dst_kpt_id = skeleton['dst_kpt_id']
                dst_kpt_x = round(bbox_keypoints[dst_kpt_id][0])
                dst_kpt_y = round(bbox_keypoints[dst_kpt_id][1])
                dst_kpt_conf = bbox_keypoints[dst_kpt_id][2]  # 获取终止点置信度
                # print(dst_kpt_conf)
                # 获取骨架连接颜色
                skeleton_color = skeleton['color']
                # 获取骨架连接线宽
                skeleton_thickness = skeleton['thickness']
                # 如果起始点和终止点的置信度都高于阈值，才画骨架连接
                if srt_kpt_conf > 0.5 and dst_kpt_conf > 0.5:
                    # 画骨架连接
                    img_bgr = cv2.line(img_bgr, (srt_kpt_x, srt_kpt_y), (dst_kpt_x, dst_kpt_y), color=skeleton_color,
                                    thickness=skeleton_thickness)
            # 画该框的关键点
            for kpt_id in kpt_color_map:
                # 获取该关键点的颜色、半径、XY坐标
                kpt_color = kpt_color_map[kpt_id]['color']
                kpt_radius = kpt_color_map[kpt_id]['radius']
                kpt_x = round(bbox_keypoints[kpt_id][0])
                kpt_y = round(bbox_keypoints[kpt_id][1])
                kpt_conf = bbox_keypoints[kpt_id][2]  # 获取该关键点置信度
                if kpt_conf > 0.5:
                    # 画圆：图片、XY坐标、半径、颜色、线宽（-1为填充）
                    img_bgr = cv2.circle(img_bgr, (kpt_x, kpt_y), kpt_radius, kpt_color, -1)
        plt.imshow(img_bgr[:, :, ::-1])
        plt.show()
    
    
        # 假设 img_bgr 是你的 BGR 格式图像
        plt.imsave(dir, img_bgr[:, :, ::-1])  # [:, :, ::-1] 将 BGR 转换为 RGB

**判断越界代码**

首先要确定危险区域，设计为一个多边形。越界设计为，脚踏入危险区域，或者在危险区域边界线上。

怎么样确定这个多边形呢？从左上角的点顺时针，给出多边形的每个点，以此连接每个点，即可确定一个唯一的多边形。

    def is_point_on_segment(p, seg_p1, seg_p2):
        """判断点是否在线段上"""
        x, y = p
        x1, y1 = seg_p1
        x2, y2 = seg_p2
    
        # 计算叉积判断是否共线
        cross = (x2 - x1) * (y - y1) - (y2 - y1) * (x - x1)
        if abs(cross) > 1e-10:
            return False
    
        # 检查点是否在线段的包围盒内
        min_x = min(x1, x2)
        max_x = max(x1, x2)
        min_y = min(y1, y2)
        max_y = max(y1, y2)
    
        if not (min_x - 1e-10 <= x <= max_x + 1e-10):
            return False
        if not (min_y - 1e-10 <= y <= max_y + 1e-10):
            return False
    
        return True
    
    def is_point_in_polygon(point, polygon):
        """判断点是否在多边形内部"""
        x, y = point
        n = len(polygon)
        if n < 3:
            return False  # 非多边形
    
        # 检查点是否在任一边上
        for i in range(n):
            p1 = polygon[i]
            p2 = polygon[(i + 1) % n]
            if is_point_on_segment((x, y), p1, p2):
                return True
    
        # 使用射线法判断内部
        inside = False
        for i in range(n):
            p1 = polygon[i]
            p2 = polygon[(i + 1) % n]
            x1, y1 = p1
            x2, y2 = p2
    
            # 判断边是否跨越射线上方和下方
            if (y1 > y) != (y2 > y):
                # 计算交点x坐标
                t = (y - y1) / (y2 - y1)
                x_intersect = x1 + t * (x2 - x1)
                if x_intersect > x:
                    inside = not inside
    
        return inside

**示例用法**

    if __name__=='__main__':
        # 从左上角的点顺时针，给出多边形的每个点
        polygon = [(0, 0), (0, 2), (2, 2), (2, 0)]  # 矩形
        # polygon = [(0, 0), (0, 2), (1, 2), (2, 1), (2, 0)]  # 五边形
        point_inside = (1, 1)
        point_outside = (1, 2)
        point_on_edge = (1, 0)
    
        print(is_point_in_polygon(point_inside, polygon))    # 输出：True
        print(is_point_in_polygon(point_outside, polygon))   # 输出：False
        print(is_point_in_polygon(point_on_edge, polygon))  # 输出：True

### YOLO实现 {#YOLOcomplete}

**引入库**

    from ultralytics import YOLO
    import cv2
    import matplotlib.pyplot as plt
    import torch
    
    import sys
    sys.path.append("/home/zengz/zz/ll/Yolov11/")
    from utils.tools_area_foot import is_point_in_polygon,draw_s,draw
    
**检测方法：**

yolo对于没有检测到的关节点坐标设置为(0,0)。

首先判断是否检测到人脚，如果检测到了，用人脚是否越界作为评判标准；如果没有检测到人脚，则以检测框中心是否越界作为评判标准。
    
    #区域入侵检测，area为区域的坐标，bboxes_keypoints为人体关节点的坐标
    def detect(area, results):
        bboxes_xyxy = results[0].boxes.xyxy.cpu().numpy().astype('uint32')
        bboxes_keypoints = results[0].keypoints.data.cpu().numpy()
        num_bbox = len(results[0].boxes.cls)
    
        labels = []
        for idx in range(num_bbox):  # 遍历每个框
            bbox_xyxy = bboxes_xyxy[idx]
            center_x = (bbox_xyxy[0]+bbox_xyxy[2]) / 2
            center_y = (bbox_xyxy[1]+bbox_xyxy[3]) / 2
            center_point = (center_x, center_y)
    
            bbox_keypoints = bboxes_keypoints[idx]  # 该框所有关键点坐标和置信度
            Right_Knee_point = tuple(bbox_keypoints[13][:2])
            Left_Knee_point = tuple(bbox_keypoints[14][:2])
            Right_Ankle_point = tuple(bbox_keypoints[15][:2])
            Left_Ankle_point = tuple(bbox_keypoints[16][:2])
    
            label = False
            #如果没有检测到这几个关节，判断中心点是否越界
            if Right_Knee_point == (0,0) and Right_Knee_point == (0,0) and Right_Knee_point == (0,0) and Right_Knee_point == (0,0):
                center_label = is_point_in_polygon(center_point, area) 
                label = center_label
            else: #只要检测到一个脚的关节点，依照关节点判断
                if Right_Knee_point == (0,0): #防止没有检测到的关节点误判为关节点位置在(0,0)，形成区域入侵
                    Right_Knee_label = False
                else:
                    Right_Knee_label = is_point_in_polygon(Right_Knee_point, area)
                if Left_Knee_point == (0,0):
                    Left_Knee_label = False
                else:
                    Left_Knee_label = is_point_in_polygon(Left_Knee_point, area)
                if Right_Ankle_point == (0,0):
                    Right_Ankle_label = False
                else:
                    Right_Ankle_label = is_point_in_polygon(Right_Ankle_point, area)
                if Left_Ankle_point == (0,0):
                    Left_Ankle_label = False
                else:
                    Left_Ankle_label = is_point_in_polygon(Left_Ankle_point, area)
                label = Right_Knee_label or Left_Knee_label or Right_Ankle_label or Left_Ankle_label
                # print(Right_Knee_label, Left_Knee_label, Right_Ankle_label,Left_Ankle_label) 
    
            if label:
                labels.append(True) #True表示入侵
                print(center_point,Right_Knee_point, Left_Knee_point, Right_Ankle_point,Left_Ankle_point)
            else:
                labels.append(False)
        print(labels)
        return labels

**使用示例：**
    
    if __name__ == '__main__':
        # 有 GPU 就用 GPU，没有就用 CPU
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        print('device:', device)
        # 载入预训练模型
        model = YOLO('/home/zengz/zz/ll/Yolov11/model/yolo11s-pose.pt')
        model.to(device)
        img_path = r'/home/zengz/zz/ll/Yolov11/dataset/pic/5.png'
        # results = model(img_path)
    
        results = model(
            source=img_path,
            classes=[0],     # 只检测人（COCO 类别 0）
            conf=0.2,  # 关键点置信度阈值
        )
    
        original_img = results[0].orig_img #(333, 137, 3) (width, height, 3)
    
        area = [(200,0),(400,300)]
        plogon = [(200,0),(400,0),(400,300),(200,300)]
    
        labels = detect(plogon, results)
    
        # #画图
        dir = '/home/zengz/zz/ll/Yolov11/detect_result/pose/5.png'
        draw(area, results, img_path, dir, labels)


上述姿势估计的方法只能检测到17个关节点，无法检测到脚部关节点

## 目标检测的方法

在yolo原有检测80个类别的基础上，新增人脚的检测。

数据集来源：https://blog.csdn.net/weixin_44338329/article/details/129037393

### 训练模型代码 {#train_detect_foot}

    from ultralytics import YOLO
    import torch
    
    # 加载预训练模型
    model = YOLO('/home/zengz/zz/ll/Yolov11/model/yolov8l.pt')  # 使用YOLOv8 Nano模型
    # 训练模型
    results = model.train(
        data='/home/zengz/zz/ll/Yolov11/configs/foot.yaml',  # 数据集配置文件路径
        epochs=100,                                # 训练轮数
        imgsz=640,                                 # 输入图片尺寸
        batch=4,                                  # 批量大小
        device='cuda' if torch.cuda.is_available() else 'cpu'  # 使用GPU或CPU
    )

foot.yaml配置

    # Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
    path: /home/zengz/zz/ll/Yolov11/datasets/foot # dataset root dir
    train: images/train # train images (relative to 'path') 128 images
    val: images/train # val images (relative to 'path') 128 images
    test: # test images (optional)
    
    # Classes
    names:
      0: person
      1: double_foot
      2: single_foot
      3: double_leg
      4: single_leg
      5: under_body

### 人脚越界检测

    import os
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
    from ultralytics import YOLO
    import cv2
    
    import sys
    sys.path.append("/home/zengz/zz/ll/Yolov11/")
    
    from utils.tools_area_foot import is_inside,draw_foot
    import json
    
    # 加载模型
    model = YOLO('/home/zengz/zz/ll/Yolov11/runs/detect/train2/weights/best.pt')
    
    # 处理单张图片
    input_dir = 'dataset/pic/'
    pic = '1.png'
    image_path = input_dir+pic # 替换为你的图片路径
    results = model.predict(
        image_path,
        classes=[2],  # 只检测行人的每只脚（class=2）
        show=True,
        conf=0.05,   # 降低置信度阈值以检测更多目标
        iou=0.3,     # 降低NMS的IoU阈值，保留更多密集目标
        imgsz=1280,  # 增大输入分辨率以检测小目标
        augment=True,  # 启用多尺度推理增强
    )
    
    # 获取带检测框的图片
    result = results[0]  # 获取第一个结果（因为我们只处理一张图片） array类型
    original_img = result.orig_img  # 获取原始图片
    
    
    # 获取当前帧的检测信息
    boxes = result.boxes.xyxy.cpu().numpy()  # 边界框坐标 [x1, y1, x2, y2]
    confs = result.boxes.conf.cpu().numpy()  # 置信度
    
    # 检测是否越界
    polygon = [(200,100),(400,100),(400,300),(300,400),(100,300)] 
    labels = is_inside(boxes, polygon)
    
    # 存储当前帧的检测的数据
    frame_info = {
        "num_people": len(result),
        "boxes": boxes.tolist(),  # 转为列表方便存储
        "confs": confs.tolist()
    }
    
    # 保存图片
    output_dir_pic = 'detect_result/picture/'
    output_image_path = output_dir_pic+'detected_inside_'+ pic
    
    draw_foot(original_img, boxes,labels,polygon,output_image_path)

### 越界判断函数 {#is_inside}

    def is_inside(boxes, plogon): 
        n = len(boxes) #场景中双脚的数量
        labels = [] #生成标签 True表示越界，False表示没有越界
        for i in range(n):
            left_up = tuple(boxes[i][:2])
            left_up_label = is_point_in_polygon(left_up, plogon)
            right_up = tuple([boxes[i][2],boxes[i][1]])
            right_up_label = is_point_in_polygon(right_up, plogon)
            right_down = tuple(boxes[i][2:])
            right_down_label = is_point_in_polygon(right_down, plogon)
            left_down = tuple([boxes[i][0],boxes[i][3]])
            left_down_label = is_point_in_polygon(left_down, plogon)
    
            if left_up_label or right_up_label or right_down_label or left_down_label:
                labels.append(True)
            else:
                labels.append(False)
        return labels

### 画图工具 {#draw_foot}
    
    def draw_foot(image, boxes, labels, polygon, output_img_dir):
        """
        在图像上只绘制行人脚部的检测框
        
        参数:
            image: 原始图像 (numpy数组)
            boxes: 检测框列表 [x1, y1, x2, y2]
            labels: 对应每个检测框是否为越界 (True/False列表)
        
        返回:
            绘制后的图像 (numpy数组)
        """
        # 创建图像副本
        plotted_img = image.copy()
    
        polygon_pts = np.array(polygon, dtype=np.int32)
    
        # 重整形数组以满足cv2.polylines的要求（每个点必须是[x,y]格式）
        polygon_pts = polygon_pts.reshape((-1, 1, 2))
    
        # 绘制多边形
        # 蓝色边框，厚度为2像素
        cv2.polylines(plotted_img, [polygon_pts], isClosed=True, color=(0, 0, 255), thickness=2)
        
        # 只绘制独行人的框
        for box, label in zip(boxes, labels):
            if label==True:  # 如果越界
                color = (255, 0, 0)  # 红色框
                status = "inside" # 添加标签文本
            else:
                color = (0, 255, 0)  # 绿色框
                status = "outside" # 添加标签文本
    
            x1, y1, x2, y2 = map(int, box)
            # 绘制矩形框 (BGR颜色格式)
            
            thickness = 2
            cv2.rectangle(plotted_img, (x1, y1), (x2, y2), color, thickness)
            
            # 设置字体
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            text_thickness = 2
            (text_width, text_height), _ = cv2.getTextSize(status, font, font_scale, text_thickness)
            
            # 文本背景
            cv2.rectangle(plotted_img, (x1, y1 - text_height - 5), (x1 + text_width, y1), color, -1)
            # 文本
            cv2.putText(plotted_img, status, (x1, y1 - 5), font, font_scale, (0, 0, 0), text_thickness)
        
        cv2.imwrite(output_img_dir, plotted_img[:, :, ::-1])  # OpenCV使用BGR格式，需要转换
        print(f"检测结果图片已保存到 {output_img_dir}")

