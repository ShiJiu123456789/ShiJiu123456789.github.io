# 小样本学习

**小样本（few-shot）情境：**

小样本（few-shot）学习是一种机器学习方法，旨在通过非常少量的训练示例来完成任务。在这种情境下，模型不需要大量的标注数据，而是利用少量的示例（甚至只有一两个），加上其预训练过程中获得的知识，来完成特定任务。

在自然语言处理中的few-shot情境通常有以下几种表现形式：

## 零样本学习（Zero-shot learning）

Zero-shot learning 就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。

例如，给定一个未见过的任务描述，模型依靠理解语言的结构和语义去生成合理的输出。
假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别斑马，那么我们需要告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。

### clip模型

学习链接：https://blog.csdn.net/lsb2002/article/details/132275132

经典论文：Learning Transferable Visual Models From Natural Language Supervision

CLIP惊艳之处在于架构非常简洁且效果好到难以置信，在zero-shot文本-图像检索，zero-shot图像分类，文本→图像生成任务guidance，open-domain 检测分割等任务上均有非常惊艳的表现。

本文探索训练一个系统来解决可能的更容易的代理任务，即预测图像与哪段文本最匹配，而不是预测文本的确切单词。

![CLIP_structure.png](CLIP_structure.png)

**训练实现：**

给定一个batch的 N个（图像, 文本）对，CLIP被训练用来预测在一个batch中实际发生的 N×N个可能的（图像, 文本）对的相似度。
为此，CLIP通过联合训练图像编码器和文本编码器来学习多模态嵌入空间，以最大化batch内 N 个真实对的图像和文本嵌入的余弦相似度，
同时最小化 N^2−N 个错误对的嵌入的余弦相似度。在这些相似度得分上优化一个对称的交叉熵损失。

**对未知类别的预测步骤:**

(1) 定义新类别的文本描述

假设新类别为 "斑马"（训练时未出现），需为其生成文本描述：

使用预设模板（如 "a photo of a {}"）格式化：

    text_descriptions = ["a photo of a zebra", "an image of a zebra", ...]  # 可扩展多个模板

文本编码：通过CLIP的文本编码器（Transformer）提取这些描述的语义特征 t_zebra。

(2) 图像特征提取

对测试图像（如一张斑马照片），通过视觉编码器（ViT/ResNet）提取特征 v。

(3) 跨模态相似度计算

计算图像特征 v 与所有新类别文本特征 t_c（如斑马、长颈鹿等）的余弦相似度：

预测结果：选择相似度最高的文本对应的类别。

### 零样本学习面临的问题

（1）领域漂移问题：同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。

（2）枢纽点问题：

（3）语义间隔：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。

## 少样本学习（Few-shot learning）

给模型待预测类别的少量样本，然后让模型通过查看该类别的其他样本来预测该类别。比如：给小孩子看一张熊猫的照片，那么小孩子到动物园看见熊猫的照片之后，就可以识别出那是熊猫。

希望机器学习模型在学习了一定类别的大量数据后，对于新的类别，只需要少量的样本就能快速学习。

## 单样本学习（One-shot learning）

模型仅通过一个示例就能学会执行任务。比如，给模型提供一对输入-输出对，它能够学习到如何对其他类似输入产生正确的输出。
One-shot learning 属于Few-shot learning的一种特殊情况。单样本学习的一个例子是，智能手机中使用的人脸识别技术。

